Humans usually have conversations by making use of prior
knowledge about a topic and background information of the
people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive
information, and thus they have a limitation in generating the
utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized
conversation (FoCus) dataset where the customized answers
are built with the user’s persona and Wikipedia knowledge. To
evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and
GPT-2 as well as transformer-based models. We assess their
generation abilities with automatic scores and conduct human
evaluations for qualitative results. We examine whether the
model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge
grounding (KG). Moreover, we show that the utterances of our
data are constructed with the proper knowledge and persona
through grounding quality assessment.
Introduction
A person who is asked by a vegetarian to suggest a restaurant in New York City would not usually recommend Wolfgang’s Steakhouse. When people give information to others,
they consider the background of the person whom they are
talking to. Following this manner of humans’ conversation, a
conversational agent’s ability to have a conversation with customized answers from prior knowledge and user’s personal
information is crucial for satisfying the users. For example,
as exemplified in Figure 1, the answer that considers both
the user’s persona and knowledge is much more attractive as
well as informative.
Research for human-machine dialog has achieved significant success recently, owing to the advance of diverse dialog
datasets (Adiwardana et al. 2020; Zhang et al. 2019b; Shuster
et al. 2019; Li et al. 2017; Lowe et al. 2015) and pre-trained
language models (Raffel et al. 2019; Clark et al. 2020; Brown
∗These authors contributed equally.
†These authors are the corresponding authors.
Copyright © 2022, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
Figure 1: Objective of FoCus dataset. In contrast to the general answer, which only gives basic information, the machine’s answer of FoCus dataset is more knowledgeable and
customized, reflecting both knowledge and persona.
et al. 2020). Despite the remarkable success, the model’s
ability to give knowledge-grounded answers reflecting user’s
personal information remains largely limited.
There exist several datasets and models that consider
the user’s persona, such as preference, interest or experience (Majumder et al. 2020; Xu et al. 2020; Wu et al. 2019;
Zhang et al. 2018; Rashkin et al. 2018; Shuster et al. 2018; Li
et al. 2017; Joshi, Mi, and Faltings 2017), which contributes
to building an agent that can talk about the user’s feelings and
interests. Though the dialog agent can access to the persona,
the absence of knowledge often limits its ability of generating
answers with specialized knowledge.
Meanwhile, to build a dialog agent that generates more
knowledgeable answers, datasets with the informative answers have been released (Dinan et al. 2018; Zhou, Prabhumoye, and Black 2018). In these datasets, the dialog agents
learn to retrieve the required knowledge from the document.
However, these datasets do not consider the user’s persona,